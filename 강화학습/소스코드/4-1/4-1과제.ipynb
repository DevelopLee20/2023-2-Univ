{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e989f3c7-51d6-418e-a95d-6e0a8796d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env.py\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import Button\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "PhotoImage = ImageTk.PhotoImage\n",
    "UNIT = 100  # 픽셀 수\n",
    "HEIGHT = 5  # 그리드월드 세로\n",
    "WIDTH = 5  # 그리드월드 가로\n",
    "TRANSITION_PROB = 1\n",
    "POSSIBLE_ACTIONS = [0, 1, 2, 3]  # 좌, 우, 상, 하\n",
    "ACTIONS = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # 좌표로 나타낸 행동\n",
    "REWARDS = []\n",
    "\n",
    "\n",
    "class GraphicDisplay(tk.Tk):\n",
    "    def __init__(self, agent):\n",
    "        super(GraphicDisplay, self).__init__()\n",
    "        self.title('Policy Iteration')\n",
    "        self.geometry('{0}x{1}'.format(HEIGHT * UNIT, HEIGHT * UNIT + 50))\n",
    "        self.texts = []\n",
    "        self.arrows = []\n",
    "        self.env = Env()\n",
    "        self.agent = agent\n",
    "        self.evaluation_count = 0\n",
    "        self.improvement_count = 0\n",
    "        self.is_moving = 0\n",
    "        (self.up, self.down, self.left, self.right), self.shapes = self.load_images()\n",
    "        self.canvas = self._build_canvas()\n",
    "        self.text_reward(2, 2, \"R : 1.0\")\n",
    "        self.text_reward(1, 2, \"R : -1.0\")\n",
    "        self.text_reward(2, 1, \"R : -1.0\")\n",
    "\n",
    "    def _build_canvas(self):\n",
    "        canvas = tk.Canvas(self, bg='white',\n",
    "                           height=HEIGHT * UNIT,\n",
    "                           width=WIDTH * UNIT)\n",
    "        # 버튼 초기화\n",
    "        iteration_button = Button(self, text=\"Evaluate\",\n",
    "                                  command=self.evaluate_policy)\n",
    "        iteration_button.configure(width=10, activebackground=\"#33B5E5\")\n",
    "        canvas.create_window(WIDTH * UNIT * 0.13, HEIGHT * UNIT + 10,\n",
    "                             window=iteration_button)\n",
    "        policy_button = Button(self, text=\"Improve\",\n",
    "                               command=self.improve_policy)\n",
    "        policy_button.configure(width=10, activebackground=\"#33B5E5\")\n",
    "        canvas.create_window(WIDTH * UNIT * 0.37, HEIGHT * UNIT + 10,\n",
    "                             window=policy_button)\n",
    "        policy_button = Button(self, text=\"move\", command=self.move_by_policy)\n",
    "        policy_button.configure(width=10, activebackground=\"#33B5E5\")\n",
    "        canvas.create_window(WIDTH * UNIT * 0.62, HEIGHT * UNIT + 10,\n",
    "                             window=policy_button)\n",
    "        policy_button = Button(self, text=\"reset\", command=self.reset)\n",
    "        policy_button.configure(width=10, activebackground=\"#33B5E5\")\n",
    "        canvas.create_window(WIDTH * UNIT * 0.87, HEIGHT * UNIT + 10,\n",
    "                             window=policy_button)\n",
    "\n",
    "        # 그리드 생성\n",
    "        for col in range(0, WIDTH * UNIT, UNIT):  # 0~400 by 80\n",
    "            x0, y0, x1, y1 = col, 0, col, HEIGHT * UNIT\n",
    "            canvas.create_line(x0, y0, x1, y1)\n",
    "        for row in range(0, HEIGHT * UNIT, UNIT):  # 0~400 by 80\n",
    "            x0, y0, x1, y1 = 0, row, HEIGHT * UNIT, row\n",
    "            canvas.create_line(x0, y0, x1, y1)\n",
    "\n",
    "        # 캔버스에 이미지 추가\n",
    "        self.rectangle = canvas.create_image(50, 50, image=self.shapes[0])\n",
    "        canvas.create_image(250, 150, image=self.shapes[1])\n",
    "        canvas.create_image(150, 250, image=self.shapes[1])\n",
    "        canvas.create_image(250, 250, image=self.shapes[2])\n",
    "\n",
    "        canvas.pack()\n",
    "\n",
    "        return canvas\n",
    "\n",
    "    def load_images(self):\n",
    "        up = PhotoImage(Image.open(\"../img/up.png\").resize((13, 13)))\n",
    "        right = PhotoImage(Image.open(\"../img/right.png\").resize((13, 13)))\n",
    "        left = PhotoImage(Image.open(\"../img/left.png\").resize((13, 13)))\n",
    "        down = PhotoImage(Image.open(\"../img/down.png\").resize((13, 13)))\n",
    "        rectangle = PhotoImage(Image.open(\"../img/rectangle.png\").resize((65, 65)))\n",
    "        triangle = PhotoImage(Image.open(\"../img/triangle.png\").resize((65, 65)))\n",
    "        circle = PhotoImage(Image.open(\"../img/circle.png\").resize((65, 65)))\n",
    "        return (up, down, left, right), (rectangle, triangle, circle)\n",
    "\n",
    "    def reset(self):\n",
    "        if self.is_moving == 0:\n",
    "            self.evaluation_count = 0\n",
    "            self.improvement_count = 0\n",
    "            for i in self.texts:\n",
    "                self.canvas.delete(i)\n",
    "\n",
    "            for i in self.arrows:\n",
    "                self.canvas.delete(i)\n",
    "            self.agent.value_table = [[0.0] * WIDTH for _ in range(HEIGHT)]\n",
    "            self.agent.policy_table = ([[[0.25, 0.25, 0.25, 0.25]] * WIDTH\n",
    "                                        for _ in range(HEIGHT)])\n",
    "            self.agent.policy_table[2][2] = []\n",
    "            x, y = self.canvas.coords(self.rectangle)\n",
    "            self.canvas.move(self.rectangle, UNIT / 2 - x, UNIT / 2 - y)\n",
    "\n",
    "    def text_value(self, row, col, contents, font='Helvetica', size=10,\n",
    "                   style='normal', anchor=\"nw\"):\n",
    "        origin_x, origin_y = 85, 70\n",
    "        x, y = origin_y + (UNIT * col), origin_x + (UNIT * row)\n",
    "        font = (font, str(size), style)\n",
    "        text = self.canvas.create_text(x, y, fill=\"black\", text=contents,\n",
    "                                       font=font, anchor=anchor)\n",
    "        return self.texts.append(text)\n",
    "\n",
    "    def text_reward(self, row, col, contents, font='Helvetica', size=10,\n",
    "                    style='normal', anchor=\"nw\"):\n",
    "        origin_x, origin_y = 5, 5\n",
    "        x, y = origin_y + (UNIT * col), origin_x + (UNIT * row)\n",
    "        font = (font, str(size), style)\n",
    "        text = self.canvas.create_text(x, y, fill=\"black\", text=contents,\n",
    "                                       font=font, anchor=anchor)\n",
    "        return self.texts.append(text)\n",
    "\n",
    "    def rectangle_move(self, action):\n",
    "        base_action = np.array([0, 0])\n",
    "        location = self.find_rectangle()\n",
    "        self.render()\n",
    "        if action == 0 and location[0] > 0:  # 상\n",
    "            base_action[1] -= UNIT\n",
    "        elif action == 1 and location[0] < HEIGHT - 1:  # 하\n",
    "            base_action[1] += UNIT\n",
    "        elif action == 2 and location[1] > 0:  # 좌\n",
    "            base_action[0] -= UNIT\n",
    "        elif action == 3 and location[1] < WIDTH - 1:  # 우\n",
    "            base_action[0] += UNIT\n",
    "        # move agent\n",
    "        self.canvas.move(self.rectangle, base_action[0], base_action[1])\n",
    "\n",
    "    def find_rectangle(self):\n",
    "        temp = self.canvas.coords(self.rectangle)\n",
    "        x = (temp[0] / 100) - 0.5\n",
    "        y = (temp[1] / 100) - 0.5\n",
    "        return int(y), int(x)\n",
    "\n",
    "    def move_by_policy(self):\n",
    "        if self.improvement_count != 0 and self.is_moving != 1:\n",
    "            self.is_moving = 1\n",
    "\n",
    "            x, y = self.canvas.coords(self.rectangle)\n",
    "            self.canvas.move(self.rectangle, UNIT / 2 - x, UNIT / 2 - y)\n",
    "\n",
    "            x, y = self.find_rectangle()\n",
    "            while len(self.agent.policy_table[x][y]) != 0:\n",
    "                self.after(100,\n",
    "                           self.rectangle_move(self.agent.get_action([x, y])))\n",
    "                x, y = self.find_rectangle()\n",
    "            self.is_moving = 0\n",
    "\n",
    "    def draw_one_arrow(self, col, row, policy):\n",
    "        if col == 2 and row == 2:\n",
    "            return\n",
    "\n",
    "        if policy[0] > 0:  # up\n",
    "            origin_x, origin_y = 50 + (UNIT * row), 10 + (UNIT * col)\n",
    "            self.arrows.append(self.canvas.create_image(origin_x, origin_y,\n",
    "                                                        image=self.up))\n",
    "        if policy[1] > 0:  # down\n",
    "            origin_x, origin_y = 50 + (UNIT * row), 90 + (UNIT * col)\n",
    "            self.arrows.append(self.canvas.create_image(origin_x, origin_y,\n",
    "                                                        image=self.down))\n",
    "        if policy[2] > 0:  # left\n",
    "            origin_x, origin_y = 10 + (UNIT * row), 50 + (UNIT * col)\n",
    "            self.arrows.append(self.canvas.create_image(origin_x, origin_y,\n",
    "                                                        image=self.left))\n",
    "        if policy[3] > 0:  # right\n",
    "            origin_x, origin_y = 90 + (UNIT * row), 50 + (UNIT * col)\n",
    "            self.arrows.append(self.canvas.create_image(origin_x, origin_y,\n",
    "                                                        image=self.right))\n",
    "\n",
    "    def draw_from_policy(self, policy_table):\n",
    "        for i in range(HEIGHT):\n",
    "            for j in range(WIDTH):\n",
    "                self.draw_one_arrow(i, j, policy_table[i][j])\n",
    "\n",
    "    def print_value_table(self, value_table):\n",
    "        for i in range(WIDTH):\n",
    "            for j in range(HEIGHT):\n",
    "                self.text_value(i, j, round(value_table[i][j], 2))\n",
    "\n",
    "    def render(self):\n",
    "        time.sleep(0.1)\n",
    "        self.canvas.tag_raise(self.rectangle)\n",
    "        self.update()\n",
    "\n",
    "    def evaluate_policy(self):\n",
    "        self.evaluation_count += 1\n",
    "        for i in self.texts:\n",
    "            self.canvas.delete(i)\n",
    "        self.agent.policy_evaluation()\n",
    "        self.print_value_table(self.agent.value_table)\n",
    "\n",
    "    def improve_policy(self):\n",
    "        self.improvement_count += 1\n",
    "        for i in self.arrows:\n",
    "            self.canvas.delete(i)\n",
    "        self.agent.policy_improvement()\n",
    "        self.draw_from_policy(self.agent.policy_table)\n",
    "\n",
    "\n",
    "class Env:\n",
    "    def __init__(self):\n",
    "        self.transition_probability = TRANSITION_PROB\n",
    "        self.width = WIDTH\n",
    "        self.height = HEIGHT\n",
    "        self.reward = [[0] * WIDTH for _ in range(HEIGHT)]\n",
    "        self.possible_actions = POSSIBLE_ACTIONS\n",
    "        self.reward[2][2] = 1  # (2,2) 좌표 동그라미 위치에 보상 1\n",
    "        self.reward[1][2] = -1  # (1,2) 좌표 세모 위치에 보상 -1\n",
    "        self.reward[2][1] = -1  # (2,1) 좌표 세모 위치에 보상 -1\n",
    "        self.all_state = []\n",
    "\n",
    "        for x in range(WIDTH):\n",
    "            for y in range(HEIGHT):\n",
    "                state = [x, y]\n",
    "                self.all_state.append(state)\n",
    "\n",
    "    def get_reward(self, state, action):\n",
    "        next_state = self.state_after_action(state, action)\n",
    "        return self.reward[next_state[0]][next_state[1]]\n",
    "\n",
    "    def state_after_action(self, state, action_index):\n",
    "        action = ACTIONS[action_index]\n",
    "        return self.check_boundary([state[0] + action[0], state[1] + action[1]])\n",
    "\n",
    "    @staticmethod\n",
    "    def check_boundary(state):\n",
    "        state[0] = (0 if state[0] < 0 else WIDTH - 1\n",
    "                    if state[0] > WIDTH - 1 else state[0])\n",
    "        state[1] = (0 if state[1] < 0 else HEIGHT - 1\n",
    "                    if state[1] > HEIGHT - 1 else state[1])\n",
    "        return state\n",
    "\n",
    "    def get_transition_prob(self, state, action):\n",
    "        return self.transition_probability\n",
    "\n",
    "    def get_all_states(self):\n",
    "        return self.all_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b6ece0-aa54-4516-a879-aac052835448",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../img/up.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dldls\\OneDrive\\바탕 화면\\2학기 수업자료\\강화학습\\소스코드\\4-1과제.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m env \u001b[39m=\u001b[39m Env()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m value_iteration \u001b[39m=\u001b[39m ValueIteration(env)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m grid_world \u001b[39m=\u001b[39m GraphicDisplay(value_iteration)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m grid_world\u001b[39m.\u001b[39mmainloop()\n",
      "\u001b[1;32mc:\\Users\\dldls\\OneDrive\\바탕 화면\\2학기 수업자료\\강화학습\\소스코드\\4-1과제.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimprovement_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_moving \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mup, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshapes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_images()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcanvas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_canvas()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_reward(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mR : 1.0\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\dldls\\OneDrive\\바탕 화면\\2학기 수업자료\\강화학습\\소스코드\\4-1과제.ipynb Cell 2\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_images\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     up \u001b[39m=\u001b[39m PhotoImage(Image\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39m../img/up.png\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mresize((\u001b[39m13\u001b[39m, \u001b[39m13\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     right \u001b[39m=\u001b[39m PhotoImage(Image\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39m../img/right.png\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mresize((\u001b[39m13\u001b[39m, \u001b[39m13\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dldls/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/2%ED%95%99%EA%B8%B0%20%EC%88%98%EC%97%85%EC%9E%90%EB%A3%8C/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%86%8C%EC%8A%A4%EC%BD%94%EB%93%9C/4-1%EA%B3%BC%EC%A0%9C.ipynb#W1sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     left \u001b[39m=\u001b[39m PhotoImage(Image\u001b[39m.\u001b[39mopen(\u001b[39m\"\u001b[39m\u001b[39m../img/left.png\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mresize((\u001b[39m13\u001b[39m, \u001b[39m13\u001b[39m)))\n",
      "File \u001b[1;32mc:\\Users\\dldls\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../img/up.png'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ValueIteration:\n",
    "    def __init__(self, env):\n",
    "        # 환경에 대한 객체 선언\n",
    "        self.env = env\n",
    "        # 가치 함수를 2차원 리스트로 초기화\n",
    "        self.value_table = [[0.0] * env.width for _ in range(env.height)]\n",
    "        # 할인율\n",
    "        self.discount_factor = 0.9\n",
    "\n",
    "    # 벨만 최적 방정식을 통해 다음 가치 함수 계산\n",
    "    def value_iteration(self):\n",
    "        # 다음 가치함수 초기화\n",
    "        next_value_table = [[0.0] * self.env.width \n",
    "                           for _ in range(self.env.height)]\n",
    "\n",
    "        # 모든 상태에 대해서 벨만 최적방정식을 계산                           \n",
    "        for state in self.env.get_all_states():\n",
    "            # 마침 상태의 가치 함수 = 0\n",
    "            if state == [2, 2]:\n",
    "                next_value_table[state[0]][state[1]] = 0.0\n",
    "                continue\n",
    "\n",
    "            # 벨만 최적 방정식\n",
    "            value_list = []\n",
    "            for action in self.env.possible_actions:\n",
    "                next_state = self.env.state_after_action(state, action)\n",
    "                reward = self.env.get_reward(state, action)\n",
    "                next_value = self.get_value(next_state)\n",
    "                value_list.append((reward + self.discount_factor * next_value))\n",
    "\n",
    "            # 최댓값을 다음 가치 함수로 대입\n",
    "            next_value_table[state[0]][state[1]] = max(value_list)\n",
    "\n",
    "        self.value_table = next_value_table\n",
    "\n",
    "    # 현재 가치 함수로부터 행동을 반환\n",
    "    def get_action(self, state):\n",
    "        if state == [2, 2]:\n",
    "            return []\n",
    "\n",
    "        # 모든 행동에 대해 큐함수 (보상 + (감가율 * 다음 상태 가치함수))를 계산\n",
    "        value_list = []\n",
    "        for action in self.env.possible_actions:\n",
    "            next_state = self.env.state_after_action(state, action)\n",
    "            reward = self.env.get_reward(state, action)\n",
    "            next_value = self.get_value(next_state)\n",
    "            value = (reward + self.discount_factor * next_value)\n",
    "            value_list.append(value)\n",
    "\n",
    "        # 최대 큐 함수를 가진 행동(복수일 경우 여러 개)을 반환\n",
    "        max_idx_list = np.argwhere(value_list == np.amax(value_list))\n",
    "        action_list = max_idx_list.flatten().tolist()\n",
    "        return action_list\n",
    "\n",
    "    def get_value(self, state):\n",
    "        return self.value_table[state[0]][state[1]]\n",
    "\n",
    "# GridVI.py\n",
    "if __name__ == \"__main__\":\n",
    "    env = Env()\n",
    "    value_iteration = ValueIteration(env)\n",
    "    grid_world = GraphicDisplay(value_iteration)\n",
    "    grid_world.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3160d7-84d5-4270-a62e-58771c399270",
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "no display name and no $DISPLAY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 93\u001b[0m\n\u001b[1;32m     91\u001b[0m env \u001b[38;5;241m=\u001b[39m Env()\n\u001b[1;32m     92\u001b[0m policy_iteration \u001b[38;5;241m=\u001b[39m PolicyIteration(env)\n\u001b[0;32m---> 93\u001b[0m grid_world \u001b[38;5;241m=\u001b[39m \u001b[43mGraphicDisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_iteration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m grid_world\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mGraphicDisplay.__init__\u001b[0;34m(self, agent)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, agent):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mGraphicDisplay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolicy Iteration\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeometry(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124mx\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(HEIGHT \u001b[38;5;241m*\u001b[39m UNIT, HEIGHT \u001b[38;5;241m*\u001b[39m UNIT \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m50\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/rtx/lib/python3.10/tkinter/__init__.py:2299\u001b[0m, in \u001b[0;36mTk.__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2297\u001b[0m         baseName \u001b[38;5;241m=\u001b[39m baseName \u001b[38;5;241m+\u001b[39m ext\n\u001b[1;32m   2298\u001b[0m interactive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk \u001b[38;5;241m=\u001b[39m \u001b[43m_tkinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscreenName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minteractive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwantobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43museTk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msync\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m useTk:\n\u001b[1;32m   2301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loadtk()\n",
      "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class PolicyIteration:\n",
    "    def __init__(self, env):\n",
    "        # 환경에 대한 객체 선언\n",
    "        self.env = env\n",
    "        # 가치함수를 2차원 리스트로 초기화\n",
    "        self.value_table = [[0.0] * env.width for _ in range(env.height)]\n",
    "        # 상 하 좌 우 동일한 확률로 정책 초기화\n",
    "        self.policy_table = [[[0.25, 0.25, 0.25, 0.25]] * env.width\n",
    "                            for _ in range(env.height)]\n",
    "        # 마침 상태의 설정\n",
    "        self.policy_table[2][2] = []\n",
    "        # 할인율\n",
    "        self.discount_factor = 0.9\n",
    "\n",
    "    # 벨만 기대 방정식을 통해 다음 가치함수를 계산하는 정책 평가\n",
    "    def policy_evaluation(self):\n",
    "        # 다음 가치함수 초기화\n",
    "        next_value_table = [[0.00] * self.env.width\n",
    "                           for _ in range(self.env.height)]\n",
    "\n",
    "        # 모든 상태에 대해서 벨만 기대방정식을 계산\n",
    "        for state in self.env.get_all_states():\n",
    "            value = 0.0\n",
    "            # 마침 상태의 가치 함수 = 0\n",
    "            if state == [2, 2]:\n",
    "                next_value_table[state[0]][state[1]] = value\n",
    "                continue\n",
    "\n",
    "            # 벨만 기대 방정식\n",
    "            for action in self.env.possible_actions:\n",
    "                next_state = self.env.state_after_action(state, action)\n",
    "                reward = self.env.get_reward(state, action)\n",
    "                next_value = self.get_value(next_state)\n",
    "                value += (self.get_policy(state)[action] *\n",
    "                          (reward + self.discount_factor * next_value))\n",
    "\n",
    "            next_value_table[state[0]][state[1]] = value\n",
    "\n",
    "        self.value_table = next_value_table\n",
    "\n",
    "    # 현재 가치 함수에 대해서 탐욕 정책 발전\n",
    "    def policy_improvement(self):\n",
    "        next_policy = self.policy_table\n",
    "        for state in self.env.get_all_states():\n",
    "            if state == [2, 2]:\n",
    "                continue\n",
    "            \n",
    "            value_list = []\n",
    "            # 반환할 정책 초기화\n",
    "            result = [0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "            # 모든 행동에 대해서 [보상 + (할인율 * 다음 상태 가치함수)] 계산\n",
    "            for index, action in enumerate(self.env.possible_actions):\n",
    "                next_state = self.env.state_after_action(state, action)\n",
    "                reward = self.env.get_reward(state, action)\n",
    "                next_value = self.get_value(next_state)\n",
    "                value = reward + self.discount_factor * next_value\n",
    "                value_list.append(value)\n",
    "\n",
    "            # 받을 보상이 최대인 행동들에 대해 탐욕 정책 발전\n",
    "            max_idx_list = np.argwhere(value_list == np.amax(value_list))\n",
    "            max_idx_list = max_idx_list.flatten().tolist()\n",
    "            prob = 1 / len(max_idx_list)\n",
    "\n",
    "            for idx in max_idx_list:\n",
    "                result[idx] = prob\n",
    "\n",
    "            next_policy[state[0]][state[1]] = result\n",
    "\n",
    "        self.policy_table = next_policy\n",
    "\n",
    "    # 특정 상태에서 정책에 따라 무작위로 행동을 반환\n",
    "    def get_action(self, state):\n",
    "        policy = self.get_policy(state)\n",
    "        policy = np.array(policy)\n",
    "        return np.random.choice(4, 1, p=policy)[0]\n",
    "\n",
    "    # 상태에 따른 정책 반환\n",
    "    def get_policy(self, state):\n",
    "        return self.policy_table[state[0]][state[1]]\n",
    "\n",
    "    # 가치 함수의 값을 반환\n",
    "    def get_value(self, state):\n",
    "        return self.value_table[state[0]][state[1]]\n",
    "\n",
    "# GridPI.py\n",
    "if __name__ == \"__main__\":\n",
    "    env = Env()\n",
    "    policy_iteration = PolicyIteration(env)\n",
    "    grid_world = GraphicDisplay(policy_iteration)\n",
    "    grid_world.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a8446-dea7-4e6b-94bb-54084815e9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
