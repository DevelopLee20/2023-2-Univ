{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False)]},\n",
       " 1: {0: [(0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)],\n",
       "  1: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 0, 0.0, False)]},\n",
       " 2: {0: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 6, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 1, 0.0, False),\n",
       "   (0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 1, 0.0, False)]},\n",
       " 3: {0: [(0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True)],\n",
       "  1: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 3, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 3, 0.0, False),\n",
       "   (0.3333333333333333, 2, 0.0, False)]},\n",
       " 4: {0: [(0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)],\n",
       "  2: [(0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 0, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 0, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False)]},\n",
       " 5: {0: [(1.0, 5, 0, True)],\n",
       "  1: [(1.0, 5, 0, True)],\n",
       "  2: [(1.0, 5, 0, True)],\n",
       "  3: [(1.0, 5, 0, True)]},\n",
       " 6: {0: [(0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True)],\n",
       "  2: [(0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 7, 0.0, True),\n",
       "   (0.3333333333333333, 2, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)]},\n",
       " 7: {0: [(1.0, 7, 0, True)],\n",
       "  1: [(1.0, 7, 0, True)],\n",
       "  2: [(1.0, 7, 0, True)],\n",
       "  3: [(1.0, 7, 0, True)]},\n",
       " 8: {0: [(0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True)],\n",
       "  1: [(0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 9, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 4, 0.0, False),\n",
       "   (0.3333333333333333, 8, 0.0, False)]},\n",
       " 9: {0: [(0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 8, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 10, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True)],\n",
       "  3: [(0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 5, 0.0, True),\n",
       "   (0.3333333333333333, 8, 0.0, False)]},\n",
       " 10: {0: [(0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 11, 0.0, True)],\n",
       "  2: [(0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 11, 0.0, True),\n",
       "   (0.3333333333333333, 6, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 11, 0.0, True),\n",
       "   (0.3333333333333333, 6, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False)]},\n",
       " 11: {0: [(1.0, 11, 0, True)],\n",
       "  1: [(1.0, 11, 0, True)],\n",
       "  2: [(1.0, 11, 0, True)],\n",
       "  3: [(1.0, 11, 0, True)]},\n",
       " 12: {0: [(1.0, 12, 0, True)],\n",
       "  1: [(1.0, 12, 0, True)],\n",
       "  2: [(1.0, 12, 0, True)],\n",
       "  3: [(1.0, 12, 0, True)]},\n",
       " 13: {0: [(0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 13, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 12, 0.0, True),\n",
       "   (0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False)],\n",
       "  2: [(0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 9, 0.0, False),\n",
       "   (0.3333333333333333, 12, 0.0, True)]},\n",
       " 14: {0: [(0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False)],\n",
       "  1: [(0.3333333333333333, 13, 0.0, False),\n",
       "   (0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 15, 1.0, True)],\n",
       "  2: [(0.3333333333333333, 14, 0.0, False),\n",
       "   (0.3333333333333333, 15, 1.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False)],\n",
       "  3: [(0.3333333333333333, 15, 1.0, True),\n",
       "   (0.3333333333333333, 10, 0.0, False),\n",
       "   (0.3333333333333333, 13, 0.0, False)]},\n",
       " 15: {0: [(1.0, 15, 0, True)],\n",
       "  1: [(1.0, 15, 0, True)],\n",
       "  2: [(1.0, 15, 0, True)],\n",
       "  3: [(1.0, 15, 0, True)]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('FrozenLake-v1', render_mode=\"human\")\n",
    "env.env.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 - 전이확률, 다음상태, 보상, 완료여부\n",
    "custom_env = {\n",
    "    0: [\n",
    "        (0.1, 1, -2, 0),\n",
    "        (0.9, -1, 0)\n",
    "    ],\n",
    "\n",
    "    1: [\n",
    "        (0.5, 0, -1, 0),\n",
    "        (0.5, 2, -2, 0)\n",
    "    ],\n",
    "\n",
    "    2: [\n",
    "        (0.2, 6, 0, 1),\n",
    "        (0.8, 3, -2, 0)\n",
    "    ],\n",
    "\n",
    "    3: [\n",
    "        (0.4, 5, 1, 0),\n",
    "        (0.6, 4, 10, 0)\n",
    "    ],\n",
    "\n",
    "    4: [\n",
    "        (1.0, 6, 0, 1)\n",
    "    ],\n",
    "\n",
    "    5: [\n",
    "        (0.2, 1, -2, 0),\n",
    "        (0.4, 2, -2, 0),\n",
    "        (0.4, 3, -2, 0)\n",
    "    ],\n",
    "\n",
    "    6: [\n",
    "\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(0.1, 1, -2, 0), (0.9, -1, 0)],\n",
       " 1: [(0.5, 0, -1, 0), (0.5, 2, -2, 0)],\n",
       " 2: [(0.2, 6, 0, 1), (0.8, 3, -2, 0)],\n",
       " 3: [(0.4, 5, 1, 0), (0.6, 4, 10, 0)],\n",
       " 4: [(1.0, 6, 0, 1)],\n",
       " 5: [(0.2, 1, -2, 0), (0.4, 2, -2, 0), (0.4, 3, -2, 0)],\n",
       " 6: []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_env = {\n",
    "    0: {0: [(0.9, 0, -1, False), (0.1, 1, -2, False)],\n",
    "      1: [(0.9, 0, -1, False), (0.1, 1, -2, False)]},\n",
    "     1: {0: [(0.5, 0, -1, False), (0.5, 2, -2, False)],\n",
    "      1: [(0.5, 0, -1, False), (0.5, 2, -2, False)]},\n",
    "     2: {0: [(0.2, 6, 0, True), (0.8, 3, -2, False)],\n",
    "      1: [(0.2, 6, 0, True), (0.8, 3, -2, False)]},\n",
    "     3: {0: [(0.4, 4, 1, False), (0.6, 5, 10, False)],\n",
    "      1: [(0.4, 4, 1, False), (0.6, 5, 10, False)]},\n",
    "     4: {0: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)],\n",
    "      1: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)],\n",
    "      2: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)]},\n",
    "     5: {0: [(1.0, 6, 0, True)]},\n",
    "     6: {0: [(1.0, 6, 0, True)]}\n",
    "}\n",
    "\n",
    "custom_env = {\n",
    "    0: {0: [(0.9, 0, -1, False), (0.1, 1, -2, False)],\n",
    "  1: [(0.9, 0, -1, False), (0.1, 1, -2, False)],\n",
    "  2: [(0.9, 0, -1, False), (0.1, 1, -2, False)]},\n",
    " 1: {0: [(0.5, 0, -1, False), (0.5, 2, -2, False)],\n",
    "  1: [(0.5, 0, -1, False), (0.5, 2, -2, False)],\n",
    "  2: [(0.5, 0, -1, False), (0.5, 2, -2, False)]},\n",
    " 2: {0: [(0.2, 6, 0, True), (0.8, 3, -2, False)],\n",
    "  1: [(0.2, 6, 0, True), (0.8, 3, -2, False)],\n",
    "  2: [(0.2, 6, 0, True), (0.8, 3, -2, False)]},\n",
    " 3: {0: [(0.4, 4, 1, False), (0.6, 5, 10, False)],\n",
    "  1: [(0.4, 4, 1, False), (0.6, 5, 10, False)],\n",
    "  2: [(0.4, 4, 1, False), (0.6, 5, 10, False)]},\n",
    " 4: {0: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)],\n",
    "  1: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)],\n",
    "  2: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)]},\n",
    " 5: {0: [(1.0, 6, 0, True)], 1: [(1.0, 6, 0, True)], 2: [(1.0, 6, 0, True)]},\n",
    " 6: {0: [(1.0, 6, 0, True)], 1: [(1.0, 6, 0, True)], 2: [(1.0, 6, 0, True)]}\n",
    "}\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "        self.observation_space = spaces.Discrete(7)\n",
    "        self.transition_probabilities = custom_env\n",
    "        self.current_state = None\n",
    "        self.step_count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_state = 0\n",
    "        self.step_count = 0\n",
    "        return f'reset Agent in {self.current_state}.'\n",
    "\n",
    "    def step(self, action):\n",
    "        transition_info = self.transition_probabilities[self.current_state][action]\n",
    "        choicep = [i[0] for i in transition_info]\n",
    "        prob, next_state, reward, done = transition_info[np.random.choice(len(transition_info), p=choicep)]\n",
    "        self.current_state = next_state\n",
    "        self.step_count += 1\n",
    "\n",
    "        return next_state, reward, done, {\"prob\": prob}\n",
    "\n",
    "env_name = 'CustomEnv-v0'\n",
    "gym.register(env_name, entry_point = lambda: CustomEnv())\n",
    "env = gym.make(env_name)\n",
    "\n",
    "for e in range(10):\n",
    "    state = env.reset()\n",
    "    reward_sum = 0\n",
    "    \n",
    "    for t in range(500):\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, prob = env.step(action)\n",
    "        reward_sum += reward\n",
    "        print(next_state, reward, done, prob)\n",
    "\n",
    "        if done:\n",
    "            print(f'Episode finished after {t+1} timesteps, reward: {reward_sum}.')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: [(0.9, 0, -1, False), (0.1, 1, -2, False)],\n",
       "  1: [(0.9, 0, -1, False), (0.1, 1, -2, False)]},\n",
       " 1: {0: [(0.5, 0, -1, False), (0.5, 2, -2, False)],\n",
       "  1: [(0.5, 0, -1, False), (0.5, 2, -2, False)]},\n",
       " 2: {0: [(0.2, 6, 0, True), (0.8, 3, -2, False)],\n",
       "  1: [(0.2, 6, 0, True), (0.8, 3, -2, False)]},\n",
       " 3: {0: [(0.4, 4, 1, False), (0.6, 5, 10, False)],\n",
       "  1: [(0.4, 4, 1, False), (0.6, 5, 10, False)]},\n",
       " 4: {0: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)],\n",
       "  1: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)],\n",
       "  2: [(0.2, 1, -2, False), (0.4, 2, -2, False), (0.4, 3, -2, False)]},\n",
       " 5: {0: [(1.0, 6, 0, True)]},\n",
       " 6: {0: [(1.0, 6, 0, True)]}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dldls\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:174: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed a `seed` instead of using `Env.seed` for resetting the environment random number generator.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\dldls\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:187: UserWarning: \u001b[33mWARN: Future gym versions will require that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\dldls\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'int'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable float object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(goal_steps):\n\u001b[0;32m     54\u001b[0m     action \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample()\n\u001b[1;32m---> 55\u001b[0m     state, reward, done, truncated, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     56\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mstate\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mreward\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mdone\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mtruncated\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00minfo\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     57\u001b[0m     \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[1;32mc:\\Users\\dldls\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\dldls\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\wrappers\\env_checker.py:37\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchecked_step \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchecked_step \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\dldls\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:214\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[39m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m result \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m    215\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    216\u001b[0m     result, \u001b[39mtuple\u001b[39m\n\u001b[0;32m    217\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpects step result to be a tuple, actual type: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(result)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(result) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m:\n",
      "Cell \u001b[1;32mIn[8], line 36\u001b[0m, in \u001b[0;36mCustomEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_state, \u001b[39m0\u001b[39m, \u001b[39mTrue\u001b[39;00m, {}\n\u001b[0;32m     35\u001b[0m transitions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransition_probabilities[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_state][action]\n\u001b[1;32m---> 36\u001b[0m prob, next_state, reward, done \u001b[39m=\u001b[39m transitions[np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(\u001b[39mlen\u001b[39m(transitions))]\n\u001b[0;32m     37\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_state \u001b[39m=\u001b[39m next_state\n\u001b[0;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable float object"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        # 환경 초기화 코드 작성\n",
    "        self.action_space = spaces.Discrete(2)  # 이 예제에서는 이진 액션 공간으로 가정합니다.\n",
    "        self.observation_space = spaces.Discrete(7)  # 이 예제에서는 상태 공간이 7개의 상태로 가정합니다.\n",
    "        self.transition_probabilities = {\n",
    "            0: [(0.1, 1, -2, 0), (0.9, -1, 0)],\n",
    "            1: [(0.5, 0, -1, 0), (0.5, 2, -2, 0)],\n",
    "            2: [(0.2, 6, 0, 1), (0.8, 3, -2, 0)],\n",
    "            3: [(0.4, 5, 1, 0), (0.6, 4, 10, 0)],\n",
    "            4: [(1.0, 6, 0, 1)],\n",
    "            5: [(0.2, 1, -2, 0), (0.4, 2, -2, 0), (0.4, 3, -2, 0)],\n",
    "            6: []\n",
    "        }\n",
    "        self.current_state = None\n",
    "        self.step_count = 0\n",
    "        self.max_steps = 100  # 최대 단계 수\n",
    "\n",
    "    def reset(self):\n",
    "        # 환경 초기화 코드 작성\n",
    "        self.current_state = 0  # 초기 상태를 설정합니다.\n",
    "        self.step_count = 0\n",
    "        return self.current_state\n",
    "\n",
    "    def step(self, action):\n",
    "        # 행동 수행 및 보상 및 다음 상태 계산\n",
    "        if self.step_count >= self.max_steps:\n",
    "            return self.current_state, 0, True, {}\n",
    "\n",
    "        transitions = self.transition_probabilities[self.current_state][action]\n",
    "        prob, next_state, reward, done = transitions[np.random.choice(len(transitions))]\n",
    "        self.current_state = next_state\n",
    "        self.step_count += 1\n",
    "        return self.current_state, reward, done, {}\n",
    "\n",
    "# Gym 환경을 등록합니다.\n",
    "env_name = 'CustomEnv-v0'\n",
    "gym.register(env_name, entry_point=lambda: CustomEnv())\n",
    "\n",
    "# 환경을 생성합니다.\n",
    "env = gym.make(env_name)\n",
    "\n",
    "goal_steps = 500\n",
    "\n",
    "for e in range(10):\n",
    "    state = env.reset()\n",
    "\n",
    "    for t in range(goal_steps):\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, truncated, info = env.step(action)\n",
    "        print(f'{state},{reward},{done},{truncated},{info}')\n",
    "        if done:\n",
    "            print(f'Episode finished after {t+1} timesteps')\n",
    "            break\n",
    "\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
